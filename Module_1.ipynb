{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42d37e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonfunctions import *\n",
    "import cv2 as cv2\n",
    "from PIL import Image, ImageOps\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00625c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = Image.open(path)\n",
    "    img = ImageOps.exif_transpose(img) # Rotate image with camera alignment\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bbed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import hough_line, hough_line_peaks,probabilistic_hough_line, rotate\n",
    "from skimage.transform import ProjectiveTransform, warp\n",
    "from skimage.measure import find_contours\n",
    "\n",
    "def order_points(pts): # take 4 points and orders them as follows:top left,top right,bottom left,bottom right\n",
    "    rectangle=np.zeros((4,2), dtype= np.float32 )\n",
    "    \n",
    "    s=pts.sum(axis=1) # the top left 3andaha smallest x+y w bottom rught akbar\n",
    "    rectangle[0]=pts[np.argmin(s)]\n",
    "    rectangle[2]=pts[np.argmax(s)]\n",
    "    \n",
    "    difference=np.diff(pts,axis=1) # top right 3andaha smallest y-x w bottom right akbar\n",
    "    rectangle[1]=pts[np.argmin(difference)]\n",
    "    rectangle[3]=pts[np.argmax(difference)]\n",
    "    \n",
    "    return rectangle\n",
    "\n",
    "#takes 4 corners of paper and then warps them into a perfect rectangular zy akenak bt3ml scan l war2a on camscanner\n",
    "def four_point(image,pts):\n",
    "    rectangle=order_points(pts)\n",
    "    \n",
    "    top_left,top_right,bottom_right,bottom_left=rectangle\n",
    "    \n",
    "    bottom_edge_width=np.linalg.norm(bottom_right-bottom_left)\n",
    "    top_edge_width=np.linalg.norm(top_right-top_left)\n",
    "    maxwidth=int(max(bottom_edge_width,top_edge_width)) # 34an amna3 hetta tkoon cropped f ba5od el max\n",
    "\n",
    "    right_edge_height=np.linalg.norm(top_right-bottom_right)\n",
    "    left_edge_height=np.linalg.norm(top_left-bottom_left)\n",
    "    maxheight=int(max(right_edge_height,left_edge_height))\n",
    "    \n",
    "    #ba7ot el 4 ordered points into a rectangle\n",
    "    final_rectangle=np.array([[0,0],[maxwidth-1,0],[maxwidth-1,maxheight-1],[0,maxheight-1] ],dtype=np.float32 )\n",
    "    #this produces a 3x3 homography matrix which encodes rotation,translation,scaling\n",
    "    mapping=cv2.getPerspectiveTransform(rectangle,final_rectangle)\n",
    "    #to apply warping for every pixel in the paper from the top till the bottom\n",
    "    result=cv2.warpPerspective(image,mapping,(maxwidth,maxheight))\n",
    "    \n",
    "    return result\n",
    "\n",
    "#it takes image and tries to find the 4 corner points to apply warping on it\n",
    "def detect_document_contour(image):\n",
    "    gray=rgb2gray(image)\n",
    "    gray_blurred=gaussian(gray,sigma=1)\n",
    "    edges = canny(gray_blurred, sigma=1, low_threshold=30/255, high_threshold=100/255).astype(np.uint8) * 255\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))\n",
    "    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)#retr-external to retun the outer contour , msh 3ayez el table grid contour\n",
    "    if not contours:\n",
    "        return None\n",
    "\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True) # 34an a sort el contour from largest(paper) to smallest\n",
    "\n",
    "    for c in contours[:10]:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        for eps in [0.01, 0.02, 0.03, 0.04, 0.05]:\n",
    "            approx = cv2.approxPolyDP(c, eps * peri, True)\n",
    "            if len(approx) == 4:\n",
    "                return approx.reshape(4, 2)\n",
    "\n",
    "    # to get the best rectangle even if not perfect contour\n",
    "    rect = cv2.minAreaRect(contours[0])\n",
    "    box = cv2.boxPoints(rect)\n",
    "    return box.astype(np.float32)\n",
    "    \n",
    "\n",
    "def deskew(image):\n",
    "    result=np.zeros_like(image)\n",
    "    edge=canny(image,sigma=1,low_threshold=10,high_threshold=70)\n",
    "    lines=probabilistic_hough_line(edge,line_length=80,line_gap=5)\n",
    "  \n",
    "    if not lines:\n",
    "        return image\n",
    "    \n",
    "    #Storing angles of lines detected\n",
    "    angles=[]\n",
    "    \n",
    "    for(x0,y0),(x1,y1) in lines:\n",
    "        delta_x=x1-x0\n",
    "        delta_y=y1-y0\n",
    "        ang=np.degrees(np.arctan2(delta_y,delta_x))\n",
    "        \n",
    "        while ang>90:\n",
    "            ang-=180\n",
    "           \n",
    "        while ang<-90:\n",
    "            ang+=180\n",
    "            \n",
    "        angles.append(ang)\n",
    "        \n",
    "    horizontal=[a for a in angles if abs(a)<45] #to keep the sllightly tilted rows \n",
    "    if len(horizontal)<3:\n",
    "        return image  \n",
    "        \n",
    "    skew=float(np.median(horizontal)) #to avoid extreme outlier eno ybawaz el angles ely tal3a\n",
    "    skew = float(np.clip(skew, -10, 10))  # prevent over-rotation\n",
    "\n",
    "    rotated =rotate(image,angle=-skew,resize=False, preserve_range=True )\n",
    "    return rotated \n",
    "           \n",
    "def preprocessing(image):\n",
    "    doc_cont=detect_document_contour(image)\n",
    "    warped=four_point(image,doc_cont)\n",
    "    \n",
    "    image_gray = rgb2gray(warped)    \n",
    " \n",
    "    image_deskewed=deskew(image_gray)\n",
    "  \n",
    "    return image_deskewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trim_border(image, border_size=10): #Trims image by border zise\n",
    "    H, W = image.shape\n",
    "    return image[border_size:H-border_size, border_size:W-border_size]\n",
    "\n",
    "def edge_detection(image):\n",
    "    image = image.astype(np.float32) / 255.0 \n",
    "\n",
    "    # Edge Detection\n",
    "    gx = cv2.Sobel(image, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(image, cv2.CV_32F, 0, 1, ksize=3)\n",
    "\n",
    "    gx_abs = np.abs(gx)\n",
    "    gy_abs = np.abs(gy)\n",
    "\n",
    "    # Normalizes Gradients to 90th percentile\n",
    "    gx_n = gx_abs / (np.percentile(gx_abs, 90) + 1e-6)\n",
    "    gy_n = gy_abs / (np.percentile(gy_abs, 90) + 1e-6)\n",
    "\n",
    "    # Picks larger gradient and limits it to 1\n",
    "    mag_balanced = np.maximum(gx_n, gy_n)\n",
    "    mag_balanced = np.clip(mag_balanced, 0, 1)\n",
    "    \n",
    "    # Thresholding gradient to classify edges\n",
    "    edges = mag_balanced > 0.6 \n",
    "    edges = edges.astype(np.uint8) * 255\n",
    "\n",
    "    return edges\n",
    "\n",
    "def line_detection(edges, image): # Takes edges and returns intersection points of lines\n",
    "    H, W = image.shape\n",
    "    diag = int(np.hypot(H, W)) # Using diagonal to adapt parameters to different resolutions\n",
    "\n",
    "    # Initializing line detection result images\n",
    "    horizontal_lines = np.zeros_like(image)\n",
    "    vertical_lines = np.zeros_like(image)\n",
    "    intersections = np.zeros_like(image)\n",
    "\n",
    "    # Hough lines and peaks to extract prominent lines\n",
    "    acc, angles, dists = hough_line(edges)\n",
    "    acc, angles, dists = hough_line_peaks(acc, angles, dists, threshold=0.75 * np.max(acc),  \n",
    "                                        min_distance = int(0.01*diag), num_peaks=40) \n",
    "    \n",
    "    # Drawing hough lines results\n",
    "    for i in range(len(angles)): \n",
    "        theta = abs(angles[i]) \n",
    "        if not (theta < np.radians(5) or theta > np.radians(85)): # Reject diagonal lines\n",
    "            continue \n",
    "        if theta < np.radians(45): # Vertical liens\n",
    "            a = math.cos(angles[i]) \n",
    "            b = math.sin(angles[i]) \n",
    "            x0 = a * dists[i] \n",
    "            y0 = b * dists[i] \n",
    "            pt1 = (int(x0 + 10000*(-b)), int(y0 + 10000*(a))) \n",
    "            pt2 = (int(x0 - 10000*(-b)), int(y0 - 10000*(a))) \n",
    "            cv2.line(vertical_lines, pt1, pt2, (255, 255, 255), 1) \n",
    "        elif theta > np.radians(45): # Horizontal lines\n",
    "            a = math.cos(angles[i]) \n",
    "            b = math.sin(angles[i]) \n",
    "            x0 = a * dists[i] \n",
    "            y0 = b * dists[i] \n",
    "            pt1 = (int(x0 + 10000*(-b)), int(y0 + 10000*(a))) \n",
    "            pt2 = (int(x0 - 10000*(-b)), int(y0 - 10000*(a))) \n",
    "            cv2.line(horizontal_lines, pt1, pt2, (255, 255, 255), 1) \n",
    "\n",
    "    # Finding intersection points of horizontal and vertical lines\n",
    "    intersections = np.bitwise_and(horizontal_lines > 0, vertical_lines > 0) \n",
    "    points = np.argwhere(intersections == 1)\n",
    "\n",
    "    return points\n",
    "\n",
    "def cluster_1d(values, tol): # Clusters array into groups of values within tolerance\n",
    "    values = sorted(values) # Sorting array\n",
    "    clusters = [[values[0]]] # Initialize 2D array clusters with smallest value\n",
    "\n",
    "    for v in values[1:]:\n",
    "        if abs(v - clusters[-1][-1]) <= tol: # If value within tolerance of current cluster being filled append it to the end of the cluster\n",
    "            clusters[-1].append(v)\n",
    "        else: # If not start a new cluster with initial value\n",
    "            clusters.append([v])\n",
    "\n",
    "    return [int(np.mean(c)) for c in clusters] # Return mean of the clusters\n",
    "\n",
    "def cluster_rows_columns(points, y_tol, x_tol): # Performs 2D clustering of line intersection points in grid\n",
    "    xs = [p[1] for p in points] # Loading x values of intersections\n",
    "    ys = [p[0] for p in points] # Loading y values of intersections\n",
    "\n",
    "    row_ys = cluster_1d(ys, y_tol)\n",
    "    col_xs = cluster_1d(xs, x_tol)\n",
    "\n",
    "    return row_ys, col_xs\n",
    "\n",
    "def cell_extraction(image): # Takes preprocessed image and returns array of cells\n",
    "    # Remove edge of paper so it isnt considered a part of the table\n",
    "    image = trim_border(image, border_size=3) \n",
    "\n",
    "    H, W = image.shape\n",
    "\n",
    "    edges = edge_detection(image) # Detecting edges\n",
    "    points = line_detection(edges, image) # Extracting points of interection of grid\n",
    "    \n",
    "    # Tolerance dependant on image resolution\n",
    "    y_tol = 0.01 * H\n",
    "    x_tol = 0.01 * W\n",
    "\n",
    "    rows, columns = cluster_rows_columns(points, y_tol, x_tol) # Clustering of intersection points\n",
    "    \n",
    "    # Number of rows and columns\n",
    "    num_rows = len(rows) - 1\n",
    "    num_cols = len(columns) - 1\n",
    "\n",
    "    # Initializing cell images\n",
    "    cell_images = np.empty((num_rows, num_cols), dtype=object)\n",
    "    \n",
    "    for r in range(num_rows):\n",
    "        for c in range(num_cols):\n",
    "            # Cell corner points\n",
    "            x1, y1 = columns[c],   rows[r]\n",
    "            x2, y2 = columns[c+1], rows[r+1]\n",
    "\n",
    "            tl = (x1, y1)\n",
    "            br = (x2, y2)\n",
    "\n",
    "            cell_images[r, c] = image[y1:y2, x1:x2] # Extracting cell image from original image\n",
    "\n",
    "    return cell_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4a4cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# --- Define a simple CNN for MNIST ---\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64*7*7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1a3f7ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'easyocr'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpytesseract\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01measyocr\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mskimage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transform, filters, exposure, util\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'easyocr'"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "import easyocr\n",
    "from skimage import transform, filters, exposure, util\n",
    "from PIL import Image\n",
    "\n",
    "def enhance_cell_for_ocr(cell_gray, out_size=96): # Normalizing and rescaling image for handnwriting ocr\n",
    "    cell = util.img_as_float(cell_gray)  # ensure float [0..1]\n",
    "\n",
    "    cell = exposure.rescale_intensity(cell, in_range=\"image\", out_range=(0, 1))  # normalize contrast\n",
    "    cell_up = transform.resize(cell, (out_size, out_size), anti_aliasing=True, preserve_range=True)  # rescaling image\n",
    "\n",
    "    thresh = filters.threshold_sauvola(cell_up, window_size=21, k=0.2)  # local thresholding\n",
    "    binary = cell_up < thresh  # dark ink = foreground\n",
    "\n",
    "    return (binary.astype(np.uint8) * 255) \n",
    "\n",
    "def cell_preprocessing(cell_image): # Preprocesses cell image depending on requirement\n",
    "    cell_image = cell_image * 255.0\n",
    "    cell_image = median(cell_image, np.ones((2,2))) # Median filter\n",
    "\n",
    "    local_thresh = threshold_local(cell_image, block_size = 7, offset=4) # Local thresholding\n",
    "    thresholded = cell_image > local_thresh\n",
    "    thresholded = np.bitwise_invert(thresholded) # Inverting image\n",
    "\n",
    "    #show_images([cell_image, thresholded])\n",
    "\n",
    "    # Trimming border\n",
    "    size = thresholded.shape\n",
    "    thresholded = thresholded[int(size[0]*0.1):int(size[0]*0.95),\n",
    "                              int(size[1]*0.05):int(size[1]*0.9)]  # remove top 10% and right 10%\n",
    "\n",
    "    # Trimming cell border so they arent detected as symbols\n",
    "\n",
    "    row_ink = np.sum(thresholded > 0, axis=1) # Number of 1s in each row\n",
    "    col_ink = np.sum(thresholded > 0, axis=0) # Number of 1s in each column\n",
    "\n",
    "    min_row_ink = thresholded.shape[1] * 0.6  # 60% of row width\n",
    "    min_col_ink = thresholded.shape[0] * 0.6  # 60% of column height\n",
    "\n",
    "    valid_rows = np.where(row_ink < min_row_ink)[0] # Row is considered valid if less than threshold is high\n",
    "    valid_cols = np.where(col_ink < min_col_ink)[0] # Column is considered valid if less than threshold is high\n",
    "    \n",
    "    if len(valid_rows) == 0 or len(valid_cols) == 0: # If no valid rows or columns\n",
    "        raise ValueError(\"No content detected\")\n",
    "\n",
    "    y_min, y_max = valid_rows[[0, -1]] \n",
    "    x_min, x_max = valid_cols[[0, -1]]\n",
    "\n",
    "    trimmed = thresholded[y_min+1:y_max, x_min+1:x_max] # Trimmming non-valid rows and columns from image\n",
    "    \n",
    "    trimmed = binary_closing(trimmed, np.ones((3,3)))\n",
    "\n",
    "    return trimmed\n",
    "\n",
    "def check_empty_cell(cell_image): # Checks if number of non-empty pixel are more than 2%\n",
    "    ink_pixels = np.sum(cell_image > 0)\n",
    "    total_pixels = cell_image.size\n",
    "    ink_ratio = ink_pixels / total_pixels\n",
    "\n",
    "    if ink_ratio < 0.02:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def detect_question_mark(cell_image): # Not implemented, can use a binary mask with thresholding for detection\n",
    "    return False\n",
    "\n",
    "def detect_line_symbols(cell_image): # Detects box, x, check, horizontal and vertical lines in cell image\n",
    "    H, W = cell_image.shape\n",
    "    diag = int(np.hypot(H, W)) # Using diagonal to adapt parameters to different resolutions\n",
    "\n",
    "    # Initializign vound variables for horizontal, vertical and diagonal lines\n",
    "    count_h = 0\n",
    "    count_v = 0\n",
    "    count_d = 0\n",
    "\n",
    "    # Hough lines and peaks to extract prominent lines\n",
    "    acc, angles, dists = hough_line(cell_image) \n",
    "    acc, angles, dists = hough_line_peaks(acc, angles, dists, threshold=0.7 * np.max(acc),  \n",
    "                                        min_distance = int(0.07*diag), num_peaks=10) \n",
    "    \n",
    "    for i in range(len(angles)): \n",
    "        theta = abs(angles[i]) \n",
    "        if not (theta < np.radians(15) or theta > np.radians(75)): # Detecting diagonal lines\n",
    "            count_d += 1\n",
    "        elif theta < np.radians(45): # Vertical lines\n",
    "            count_v += 1\n",
    "        elif theta > np.radians(45): # Horizontal lines\n",
    "            count_h += 1\n",
    "        \n",
    "    #show_images([horizontal_lines, vertical_lines, diagonal_lines])\n",
    "\n",
    "    if count_h > 0 and count_v > 0: # Both horizontal and vertical lines present = Box (0)\n",
    "        return True, 0\n",
    "    elif count_d > 0 and count_d < 2: # Only one diagonal line detected = Check (5)\n",
    "        return True, 5\n",
    "    elif count_d > 1: # More than one diagonal line detected = x (0)\n",
    "        return True, 0\n",
    "    elif count_h == 1: # Only one horizontal line detcted = - (0)\n",
    "        return True, 0\n",
    "    elif count_h > 1: # More than one horizontal line detected = 5 - i\n",
    "        return True, 5 - count_h\n",
    "    elif count_v > 0: # Vertical lines detected = i\n",
    "        return True, count_v\n",
    "    return False, 0\n",
    "\n",
    "def ocr_check_id(cell_image): # Tesseract OCR for checking IDs\n",
    "    cell_image = (cell_image * 255.0).astype(np.uint8)\n",
    "\n",
    "    pytesseract.pytesseract.tesseract_cmd = (\n",
    "    r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "    )\n",
    "\n",
    "    # Detect digits only using specialized model\n",
    "    extracted_text = pytesseract.image_to_string(cell_image, config=\"--psm 7 digits\")\n",
    "\n",
    "    return extracted_text\n",
    "\n",
    "def ocr_check_handwriting(cell_image):\n",
    "    # Enhance and resize the image for the ocr\n",
    "    cell_image = enhance_cell_for_ocr(cell_image)\n",
    "\n",
    "    # Comditioning image for ocr\n",
    "    cell_image = np.bitwise_invert(cell_image)\n",
    "    cell_image = (cell_image * 255.0).astype(np.uint8)\n",
    "\n",
    "    cell_image = binary_opening(cell_image, np.ones((3,3)))\n",
    "    cell_image = (cell_image * 255.0).astype(np.uint8)\n",
    "    \n",
    "    # Initialize reader and read iamge only allowing digits\n",
    "    reader = easyocr.Reader(['en'], gpu=False)\n",
    "    result = reader.readtext(cell_image, allowlist='0123456789', detail=0)\n",
    "\n",
    "    if result != []:\n",
    "        return True, result[0]\n",
    "    return False, \" \"\n",
    "\n",
    "def read_cell(cell_image, ocr = \"None\"):\n",
    "    if ocr == \"id\": # Directly use tesseract for IDs without preprocessing\n",
    "        return ocr_check_id(cell_image)\n",
    "    \n",
    "    preprocessed = cell_preprocessing(cell_image)\n",
    "\n",
    "    if not check_empty_cell(preprocessed): # if cell is not empty\n",
    "        if detect_question_mark(preprocessed): # Check for '?' in cell\n",
    "            return \"?\"\n",
    "        else:\n",
    "            detection, text = ocr_check_handwriting(cell_image) # Check ocr first for digit\n",
    "            if detection: \n",
    "                return text\n",
    "            detection, line_val = detect_line_symbols(preprocessed) # Check for line symbols\n",
    "            if detection:\n",
    "                return line_val\n",
    "\n",
    "    return \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ee749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omar wael\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def Module1(import_image, export_filename):\n",
    "    image = load_image(import_image) # Load image\n",
    "\n",
    "    # Preprocessing and cell extraction\n",
    "    preprocessed_image = preprocessing(image) \n",
    "    cells = cell_extraction(preprocessed_image)\n",
    "\n",
    "    # Table values\n",
    "    values = np.empty((cells.shape[0]-1, cells.shape[1]-2), dtype=object)\n",
    "\n",
    "    # Loop on every cell\n",
    "    for r in range(1, cells.shape[0]): # Skip columns 1,2 due to them having names\n",
    "        values[r-1, 0] = read_cell(cells[r, 0], ocr=\"id\") # use OCR for IDs on first column\n",
    "        for c in range(3, cells.shape[1]):\n",
    "            cell_image = cells[r, c]\n",
    "            values[r-1, c-2] = read_cell(cell_image, ocr=\"None\")\n",
    "\n",
    "    # Export values to excel file\n",
    "    export_excel(values, export_filename, column_names = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
